{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNjGV1yN7T2isyLQamN6V24"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UBAKxdzXgeCg"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip uninstall -y diffusers transformers huggingface_hub peft\n","!pip install diffusers==0.27.2 transformers==4.37.2 huggingface_hub==0.23.4 peft==0.10.0"],"metadata":{"id":"I_hN-bGCqWX3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from diffusers import DiffusionPipeline\n","from huggingface_hub import login\n","from google.colab import userdata\n","\n","# --- 1. Log in to Hugging Face ---\n","try:\n","    hf_token = userdata.get('HF_TOKEN')\n","    login(token=hf_token)\n","    print(\"Hugging Face login successful.\")\n","except Exception as e:\n","    print(f\"Hugging Face login failed: {e}\")\n","\n","# --- 2. Define the model cache path on Google Drive ---\n","DRIVE_ROOT = \"/content/drive/MyDrive/\"\n","PROJECT_DIR = DRIVE_ROOT + \"Group14_Project/\"\n","MODEL_CACHE_DIR = PROJECT_DIR + \"Models/\"\n","\n","print(f\"Models will be loaded from: {MODEL_CACHE_DIR}\")\n","\n","# --- 3. Load SDXL Base 1.0 model ---\n","print(\"Loading SDXL Base 1.0 model to CPU...\")\n","try:\n","    base = DiffusionPipeline.from_pretrained(\n","        \"stabilityai/stable-diffusion-xl-base-1.0\",\n","        torch_dtype=torch.float16,\n","        variant=\"fp16\",\n","        use_safetensors=True,\n","        cache_dir=MODEL_CACHE_DIR\n","    )\n","    print(\"SDXL Base 1.0 successfully loaded to CPU.\")\n","except Exception as e:\n","    print(f\"Failed to load Base model: {e}\")\n","\n","# --- 4. Load SDXL Refiner 1.0 model ---\n","print(\"Loading SDXL Refiner 1.0 model to CPU...\")\n","try:\n","    refiner = DiffusionPipeline.from_pretrained(\n","        \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n","        torch_dtype=torch.float16,\n","        variant=\"fp16\",\n","        use_safetensors=True,\n","        cache_dir=MODEL_CACHE_DIR\n","    )\n","    print(\"SDXL Refiner 1.0 successfully loaded to CPU.\")\n","except Exception as e:\n","    print(f\"Failed to load Refiner model: {e}\")\n","\n","print(\"\\n--- Step 1 (modified version) complete: both models are on CPU ---\")\n"],"metadata":{"id":"iPxsAXxwhNXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import numpy as np\n","import os\n","import json\n","\n","# --- 1. Define Workloads (Updated) ---\n","PROMPT_SIMPLE = \"a high-quality photo of a cat\"\n","PROMPT_COMIC = \"a superhero landing in a city, dynamic pose, comic book style, vibrant colors\"\n","PROMPT_COMPLEX = \"Extreme close-up of an elderly human eye, highly detailed iris texture, visible skin pores and wrinkles, 8k resolution, photorealistic, cinematic lighting, macro photography\"\n","\n","# --- 2. Define Paths ---\n","DRIVE_ROOT = \"/content/drive/MyDrive/\"\n","PROJECT_DIR = DRIVE_ROOT + \"Group14_Project/\"\n","DATA_DIR = PROJECT_DIR + \"Data/\"\n","OUTPUT_JSON_PATH = os.path.join(DATA_DIR, \"measurement_results.json\")\n","\n","print(f\"Simple Prompt: {PROMPT_SIMPLE}\")\n","print(f\"Comic Prompt:  {PROMPT_COMIC}\")\n","print(f\"Complex Prompt: {PROMPT_COMPLEX}\")\n","print(f\"Data Path: {OUTPUT_JSON_PATH}\")\n","\n","if not os.path.exists(DATA_DIR):\n","    os.makedirs(DATA_DIR)"],"metadata":{"id":"BXEjGSfgZHB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fix the random seed so every generation run is consistent\n","generator = torch.Generator(device=\"cuda\").manual_seed(42)\n","\n","def run_config_high(prompt_text):\n","    \"\"\"\n","    Run the *high-quality* configuration (50 steps + Refiner),\n","    with dynamic CPU↔GPU loading to save VRAM.\n","    Returns a detailed timing breakdown.\n","    \"\"\"\n","    timings = {}\n","\n","    # --- Overall timer ---\n","    torch.cuda.synchronize()\n","    start_total = time.time()\n","\n","    # --- 1. Base model stage ---\n","    torch.cuda.synchronize()\n","    start_base_load = time.time()\n","    base.to(\"cuda\")  # move Base to GPU\n","    torch.cuda.synchronize()\n","    start_base_run = time.time()\n","\n","    latents = base(\n","        prompt=prompt_text,\n","        num_inference_steps=50,\n","        denoising_end=0.8,\n","        output_type=\"latent\",\n","        generator=generator.manual_seed(42)\n","    ).images\n","\n","    torch.cuda.synchronize()\n","    start_base_unload = time.time()\n","    base.to(\"cpu\")  # move back to CPU to free GPU memory\n","    torch.cuda.synchronize()\n","    end_base = time.time()\n","\n","    timings[\"base_load_ms\"] = (start_base_run - start_base_load) * 1000\n","    timings[\"base_run_ms\"] = (start_base_unload - start_base_run) * 1000\n","    timings[\"base_unload_ms\"] = (end_base - start_base_unload) * 1000\n","\n","    # --- 2. Refiner model stage ---\n","    torch.cuda.synchronize()\n","    start_refiner_load = time.time()\n","    refiner.to(\"cuda\")  # move Refiner to GPU\n","    torch.cuda.synchronize()\n","    start_refiner_run = time.time()\n","\n","    image = refiner(\n","        prompt=prompt_text,\n","        image=latents,\n","        num_inference_steps=50,\n","        denoising_start=0.8,\n","        generator=generator.manual_seed(42)\n","    ).images[0]\n","\n","    torch.cuda.synchronize()\n","    start_refiner_unload = time.time()\n","    refiner.to(\"cpu\")  # move back to CPU\n","    torch.cuda.synchronize()\n","    end_refiner = time.time()\n","\n","    timings[\"refiner_load_ms\"] = (start_refiner_run - start_refiner_load) * 1000\n","    timings[\"refiner_run_ms\"] = (start_refiner_unload - start_refiner_run) * 1000\n","    timings[\"refiner_unload_ms\"] = (end_refiner - start_refiner_unload) * 1000\n","\n","    # --- 3. Total latency ---\n","    torch.cuda.synchronize()\n","    end_total = time.time()\n","    timings[\"total_latency_ms\"] = (end_total - start_total) * 1000\n","\n","    return image, timings\n","\n","\n","def run_config_fast(prompt_text):\n","    \"\"\"\n","    Run the *fast* configuration (20 steps, no Refiner),\n","    with dynamic CPU↔GPU loading to conserve GPU memory.\n","    Returns a detailed timing breakdown.\n","    \"\"\"\n","    timings = {}\n","\n","    # --- Overall timer ---\n","    torch.cuda.synchronize()\n","    start_total = time.time()\n","\n","    # --- 1. Base model stage ---\n","    torch.cuda.synchronize()\n","    start_base_load = time.time()\n","    base.to(\"cuda\")  # move Base to GPU\n","    torch.cuda.synchronize()\n","    start_base_run = time.time()\n","\n","    image = base(\n","        prompt=prompt_text,\n","        num_inference_steps=20,\n","        generator=generator.manual_seed(42)\n","    ).images[0]\n","\n","    torch.cuda.synchronize()\n","    start_base_unload = time.time()\n","    base.to(\"cpu\")  # move back to CPU\n","    torch.cuda.synchronize()\n","    end_base = time.time()\n","\n","    timings[\"base_load_ms\"] = (start_base_run - start_base_load) * 1000\n","    timings[\"base_run_ms\"] = (start_base_unload - start_base_run) * 1000\n","    timings[\"base_unload_ms\"] = (end_base - start_base_unload) * 1000\n","\n","    # --- 2. No Refiner in this config ---\n","    timings[\"refiner_load_ms\"] = 0.0\n","    timings[\"refiner_run_ms\"] = 0.0\n","    timings[\"refiner_unload_ms\"] = 0.0\n","\n","    # --- 3. Total latency ---\n","    torch.cuda.synchronize()\n","    end_total = time.time()\n","    timings[\"total_latency_ms\"] = (end_total - start_total) * 1000\n","\n","    return image, timings\n","\n","print(\" Measurement functions run_config_high and run_config_fast (modified version) defined successfully.\")"],"metadata":{"id":"ebEpxNBWZg-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"--- Warming up the GPU ---\")\n","try:\n","    for i in range(3):\n","        print(f\"Warmup run {i+1}/3...\")\n","        _ = run_config_fast(prompt_text=\"warmup\")\n","    print(\" GPU warmup complete.\")\n","except Exception as e:\n","    print(f\" Warmup failed: {e}\")\n","    print(\"Check the error message. If it’s still an OOM issue, you might need to restart the runtime or switch to an A100 GPU.\")\n","\n","print(\"\\n--- Running a single test (Sanity Check) ---\")\n","\n","# --- 1. Test: High-quality config + comic prompt ---\n","print(\"Test: Config_High + PROMPT_COMIC\")\n","try:\n","    image_high, timings_high = run_config_high(PROMPT_COMIC)\n","    print(f\"  Total latency: {timings_high['total_latency_ms']:.2f} ms\")\n","    print(f\"  Base breakdown: load={timings_high['base_load_ms']:.2f} ms, run={timings_high['base_run_ms']:.2f} ms, unload={timings_high['base_unload_ms']:.2f} ms\")\n","    print(f\"  Refiner breakdown: load={timings_high['refiner_load_ms']:.2f} ms, run={timings_high['refiner_run_ms']:.2f} ms, unload={timings_high['refiner_unload_ms']:.2f} ms\")\n","except Exception as e:\n","    print(f\" Config_High test failed: {e}\")\n","\n","# --- 2. Test: Fast config + comic prompt ---\n","print(\"\\nTest: Config_Fast + PROMPT_COMIC\")\n","try:\n","    image_fast, timings_fast = run_config_fast(PROMPT_COMIC)\n","    print(f\"  Total latency: {timings_fast['total_latency_ms']:.2f} ms\")\n","    print(f\"  Base breakdown: load={timings_fast['base_load_ms']:.2f} ms, run={timings_fast['base_run_ms']:.2f} ms, unload={timings_fast['base_unload_ms']:.2f} ms\")\n","except Exception as e:\n","    print(f\" Config_Fast test failed: {e}\")\n","\n","print(\"\\n--- Step 2 (modified version) complete ---\")\n"],"metadata":{"id":"tgx9od2kaAyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm\n","\n","# --- 1. Load existing data ---\n","if os.path.exists(OUTPUT_JSON_PATH):\n","    print(f\"Found existing data at {OUTPUT_JSON_PATH}. Loading...\")\n","    with open(OUTPUT_JSON_PATH, 'r') as f:\n","        results = json.load(f)\n","else:\n","    print(\"No existing data found. Initializing new dictionary.\")\n","    results = {\n","        \"run_config\": {\n","            \"gpu_type\": \"NVIDIA T4\",\n","            \"diffusers_version\": \"0.27.2\",\n","            \"n_runs\": 50\n","        }\n","    }\n","\n","# --- 2. Initialize Keys for Complex Prompt ---\n","new_keys = [\"config_high_complex\", \"config_fast_complex\"]\n","for key in new_keys:\n","    if key not in results:\n","        print(f\"Initializing new key: {key}\")\n","        results[key] = {\n","            \"description\": f\"{'High-quality' if 'high' in key else 'Fast'} config + Complex prompt\",\n","            \"latency_distribution_ms\": [],\n","            \"breakdown_base_load_ms\": [], \"breakdown_base_run_ms\": [], \"breakdown_base_unload_ms\": [],\n","            \"breakdown_refiner_load_ms\": [], \"breakdown_refiner_run_ms\": [], \"breakdown_refiner_unload_ms\": [],\n","        }\n","\n","# --- 3. Run Experiments (Only for missing data) ---\n","N_RUNS = results[\"run_config\"][\"n_runs\"]\n","\n","try:\n","    # High + Complex\n","    key = \"config_high_complex\"\n","    current_runs = len(results[key][\"latency_distribution_ms\"])\n","    if current_runs < N_RUNS:\n","        print(f\"\\nMeasuring: {key} (Need {N_RUNS - current_runs} more runs)\")\n","        for _ in tqdm(range(N_RUNS - current_runs)):\n","            _, timings = run_config_high(PROMPT_COMPLEX)\n","            results[key][\"latency_distribution_ms\"].append(timings[\"total_latency_ms\"])\n","            # Store breakdowns...\n","            results[key][\"breakdown_base_load_ms\"].append(timings[\"base_load_ms\"])\n","            results[key][\"breakdown_base_run_ms\"].append(timings[\"base_run_ms\"])\n","            results[key][\"breakdown_base_unload_ms\"].append(timings[\"base_unload_ms\"])\n","            results[key][\"breakdown_refiner_load_ms\"].append(timings[\"refiner_load_ms\"])\n","            results[key][\"breakdown_refiner_run_ms\"].append(timings[\"refiner_run_ms\"])\n","            results[key][\"breakdown_refiner_unload_ms\"].append(timings[\"refiner_unload_ms\"])\n","    else:\n","        print(f\"Skipping {key}: Already complete.\")\n","\n","    # Fast + Complex\n","    key = \"config_fast_complex\"\n","    current_runs = len(results[key][\"latency_distribution_ms\"])\n","    if current_runs < N_RUNS:\n","        print(f\"\\nMeasuring: {key} (Need {N_RUNS - current_runs} more runs)\")\n","        for _ in tqdm(range(N_RUNS - current_runs)):\n","            _, timings = run_config_fast(PROMPT_COMPLEX)\n","            results[key][\"latency_distribution_ms\"].append(timings[\"total_latency_ms\"])\n","            # Store breakdowns...\n","            results[key][\"breakdown_base_load_ms\"].append(timings[\"base_load_ms\"])\n","            results[key][\"breakdown_base_run_ms\"].append(timings[\"base_run_ms\"])\n","            results[key][\"breakdown_base_unload_ms\"].append(timings[\"base_unload_ms\"])\n","            # Zeros for refiner\n","            results[key][\"breakdown_refiner_load_ms\"].append(0.0)\n","            results[key][\"breakdown_refiner_run_ms\"].append(0.0)\n","            results[key][\"breakdown_refiner_unload_ms\"].append(0.0)\n","    else:\n","        print(f\"Skipping {key}: Already complete.\")\n","\n","    print(\"\\n--- Complex Measurements Complete ---\")\n","\n","    # --- 4. Save Intermediate Results ---\n","    # Calculate averages\n","    for key in new_keys:\n","        data = results[key]\n","        if data[\"latency_distribution_ms\"]:\n","            data[\"avg_total_latency_ms\"] = np.mean(data[\"latency_distribution_ms\"])\n","            # (Optional: calculate other breakdown averages here if needed for report)\n","\n","    with open(OUTPUT_JSON_PATH, 'w') as f:\n","        json.dump(results, f, indent=4)\n","    print(\"Updated JSON saved.\")\n","\n","except Exception as e:\n","    print(f\"\\nError: {e}\")"],"metadata":{"id":"QJO2jMU2eVs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import json\n","import numpy as np\n","\n","print(\"--- Step 4 (Task A): Visualizing latency data ---\")\n","\n","# Load the results JSON\n","try:\n","    with open(OUTPUT_JSON_PATH, 'r') as f:\n","        results = json.load(f)\n","    print(f\"Loaded data from: {OUTPUT_JSON_PATH}\")\n","except Exception as e:\n","    print(f\"Failed to load JSON: {e}\")\n","\n","# Prepare latency distributions (convert ms → s for readability)\n","try:\n","    dist_high_simple = np.array(results[\"config_high_simple\"][\"latency_distribution_ms\"]) / 1000\n","    dist_high_comic = np.array(results[\"config_high_comic\"][\"latency_distribution_ms\"]) / 1000\n","    dist_fast_simple = np.array(results[\"config_fast_simple\"][\"latency_distribution_ms\"]) / 1000\n","    dist_fast_comic = np.array(results[\"config_fast_comic\"][\"latency_distribution_ms\"]) / 1000\n","\n","    data_to_plot = [dist_high_simple, dist_high_comic, dist_fast_simple, dist_fast_comic]\n","    labels = [\"High (Simple)\", \"High (Comic)\", \"Fast (Simple)\", \"Fast (Comic)\"]\n","\n","    # Create and save boxplot\n","    plt.figure(figsize=(10, 7))\n","    plt.boxplot(data_to_plot, labels=labels)\n","    plt.title(f'SDXL Latency Distribution on {results[\"run_config\"][\"gpu_type\"]} (N={results[\"run_config\"][\"n_runs\"]})')\n","    plt.ylabel('Total Latency (seconds)')\n","    plt.grid(True, linestyle='--', alpha=0.6)\n","\n","    VIZ_OUTPUT_PATH = os.path.join(DATA_DIR, \"latency_distribution_plot.png\")\n","    plt.savefig(VIZ_OUTPUT_PATH, dpi=300, bbox_inches='tight')\n","\n","    print(f\"\\n Plot saved to: {VIZ_OUTPUT_PATH}\")\n","    print(\"Check your Drive folder: Group14_Project/Data/latency_distribution_plot.png\")\n","\n","except Exception as e:\n","    print(f\"Error while creating plot: {e}\")\n"],"metadata":{"id":"A_tIDy-t7kiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Define Directories ---\n","IMAGE_DIR_HIGH_SIMPLE = os.path.join(DATA_DIR, \"images_high_simple\")\n","IMAGE_DIR_HIGH_COMIC = os.path.join(DATA_DIR, \"images_high_comic\")\n","IMAGE_DIR_FAST_SIMPLE = os.path.join(DATA_DIR, \"images_fast_simple\")\n","IMAGE_DIR_FAST_COMIC = os.path.join(DATA_DIR, \"images_fast_comic\")\n","\n","# [NEW] Directories for Complex Prompt\n","IMAGE_DIR_HIGH_COMPLEX = os.path.join(DATA_DIR, \"images_high_complex\")\n","IMAGE_DIR_FAST_COMPLEX = os.path.join(DATA_DIR, \"images_fast_complex\")\n","\n","image_dirs = [\n","    IMAGE_DIR_HIGH_SIMPLE, IMAGE_DIR_HIGH_COMIC, IMAGE_DIR_HIGH_COMPLEX,\n","    IMAGE_DIR_FAST_SIMPLE, IMAGE_DIR_FAST_COMIC, IMAGE_DIR_FAST_COMPLEX\n","]\n","\n","for img_dir in image_dirs:\n","    if not os.path.exists(img_dir):\n","        os.makedirs(img_dir)\n","        print(f\"Created: {img_dir}\")\n","    else:\n","        print(f\"Exists: {img_dir}\")"],"metadata":{"id":"fMoOgVwM8hew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def generate_and_save_high(prompt_text, file_path):\n","    try:\n","        # Base stage\n","        base.to(\"cuda\")\n","        latents = base(\n","            prompt=prompt_text,\n","            num_inference_steps=50,\n","            denoising_end=0.8,\n","            output_type=\"latent\"\n","        ).images\n","        base.to(\"cpu\")\n","\n","        # Refiner stage\n","        refiner.to(\"cuda\")\n","        image = refiner(\n","            prompt=prompt_text,\n","            image=latents,\n","            num_inference_steps=50,\n","            denoising_start=0.8\n","        ).images[0]\n","        refiner.to(\"cpu\")\n","\n","        # Save result\n","        image.save(file_path)\n","        return True\n","\n","    except Exception as e:\n","        print(f\"  Error while generating {file_path}: {e}\")\n","        return False\n","\n","\n","def generate_and_save_fast(prompt_text, file_path):\n","    try:\n","        base.to(\"cuda\")\n","        image = base(\n","            prompt=prompt_text,\n","            num_inference_steps=20\n","        ).images[0]\n","        base.to(\"cpu\")\n","\n","        image.save(file_path)\n","        return True\n","\n","    except Exception as e:\n","        print(f\"  Error while generating {file_path}: {e}\")\n","        return False\n","\n","\n","print(\"--- 'generate_and_save' functions defined successfully ---\")\n"],"metadata":{"id":"rP7FfYzx8kj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm\n","\n","N_IMAGES = results[\"run_config\"][\"n_runs\"]\n","print(f\"--- Generating images (Target: {N_IMAGES}) ---\")\n","\n","# --- 1. High + Complex ---\n","print(f\"\\nGenerating: {IMAGE_DIR_HIGH_COMPLEX}\")\n","for i in tqdm(range(N_IMAGES)):\n","    file_path = os.path.join(IMAGE_DIR_HIGH_COMPLEX, f\"image_{i:03d}.png\")\n","    if not os.path.exists(file_path):\n","        generate_and_save_high(PROMPT_COMPLEX, file_path)\n","\n","# --- 2. Fast + Complex ---\n","print(f\"\\nGenerating: {IMAGE_DIR_FAST_COMPLEX}\")\n","for i in tqdm(range(N_IMAGES)):\n","    file_path = os.path.join(IMAGE_DIR_FAST_COMPLEX, f\"image_{i:03d}.png\")\n","    if not os.path.exists(file_path):\n","        generate_and_save_fast(PROMPT_COMPLEX, file_path)\n","\n","print(\"Complex image generation complete.\")"],"metadata":{"id":"THY_clqahKDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# --- 1. Define the new \"Complex\" Prompt ---\n","PROMPT_COMPLEX = \"A close-up portrait of an elderly person with extremely detailed skin texture, wrinkles, and pores, 8k resolution, photorealistic, cinematic lighting\"\n","\n","print(f\"Complex Prompt defined: {PROMPT_COMPLEX}\")\n","\n","# --- 2. Define and Create New Image Directories ---\n","\n","IMAGE_DIR_HIGH_COMPLEX = os.path.join(DATA_DIR, \"images_high_complex\")\n","IMAGE_DIR_FAST_COMPLEX = os.path.join(DATA_DIR, \"images_fast_complex\")\n","\n","for img_dir in [IMAGE_DIR_HIGH_COMPLEX, IMAGE_DIR_FAST_COMPLEX]:\n","    if not os.path.exists(img_dir):\n","        os.makedirs(img_dir)\n","        print(f\"Created directory: {img_dir}\")\n","    else:\n","        print(f\"Directory exists: {img_dir}\")"],"metadata":{"id":"IZbsZPldDN0Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm\n","\n","if 'N_IMAGES_PER_CONFIG' not in locals():\n","    N_IMAGES_PER_CONFIG = 50\n","\n","print(f\"--- Generating {N_IMAGES_PER_CONFIG} images for COMPLEX prompt ---\")\n","\n","# --- 1. Generate High-Quality + Complex ---\n","print(f\"\\nGenerating in: {IMAGE_DIR_HIGH_COMPLEX}\")\n","for i in tqdm(range(N_IMAGES_PER_CONFIG)):\n","    file_name = f\"image_{i:03d}.png\"\n","    file_path = os.path.join(IMAGE_DIR_HIGH_COMPLEX, file_name)\n","\n","    # Check if file exists to avoid re-generating\n","    if not os.path.exists(file_path):\n","        generate_and_save_high(PROMPT_COMPLEX, file_path)\n","\n","# --- 2. Generate Fast + Complex ---\n","print(f\"\\nGenerating in: {IMAGE_DIR_FAST_COMPLEX}\")\n","for i in tqdm(range(N_IMAGES_PER_CONFIG)):\n","    file_name = f\"image_{i:03d}.png\"\n","    file_path = os.path.join(IMAGE_DIR_FAST_COMPLEX, file_name)\n","\n","    if not os.path.exists(file_path):\n","        generate_and_save_fast(PROMPT_COMPLEX, file_path)\n","\n","print(\"\\n--- Complex image generation complete! ---\")"],"metadata":{"id":"O5cXH_dWDQN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","import numpy as np\n","import os\n","\n","# --- 1. Load CLIP model from Hugging Face ---\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","MODEL_ID = \"openai/clip-vit-base-patch32\"\n","print(f\"Loading CLIP model: {MODEL_ID} on {device}...\")\n","\n","model = CLIPModel.from_pretrained(MODEL_ID).to(device)\n","processor = CLIPProcessor.from_pretrained(MODEL_ID)\n","print(\"CLIP model loaded successfully.\")\n","\n","# --- 2. Define Scoring Function ---\n","def compute_clip_score_for_folder(image_folder, prompt):\n","    \"\"\"Compute average CLIP similarity between all images in folder and a text prompt.\"\"\"\n","    scores = []\n","    # List files\n","    files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","    print(f\"Scoring {len(files)} images in {os.path.basename(image_folder)}...\")\n","\n","    for fname in tqdm(files):\n","        try:\n","            image_path = os.path.join(image_folder, fname)\n","            image = Image.open(image_path).convert(\"RGB\")\n","\n","            # Process inputs\n","            inputs = processor(text=[prompt], images=image, return_tensors=\"pt\", padding=True).to(device)\n","\n","            with torch.no_grad():\n","                outputs = model(**inputs)\n","                # logits_per_image is the similarity score\n","                score = outputs.logits_per_image.squeeze().item()\n","                scores.append(score)\n","        except Exception as e:\n","            print(f\"Error processing {fname}: {e}\")\n","\n","    avg_score = float(np.mean(scores)) if scores else 0.0\n","    return avg_score"],"metadata":{"id":"ye8NCMb6DSJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","# --- 1. Compute Scores for ALL 6 Configs ---\n","quality_scores = {}\n","\n","# List of (Key Name, Prompt, Folder Path)\n","tasks = [\n","    (\"high_simple\", PROMPT_SIMPLE, IMAGE_DIR_HIGH_SIMPLE),\n","    (\"high_comic\",  PROMPT_COMIC,  IMAGE_DIR_HIGH_COMIC),\n","    (\"high_complex\", PROMPT_COMPLEX, IMAGE_DIR_HIGH_COMPLEX), # NEW\n","    (\"fast_simple\", PROMPT_SIMPLE, IMAGE_DIR_FAST_SIMPLE),\n","    (\"fast_comic\",  PROMPT_COMIC,  IMAGE_DIR_FAST_COMIC),\n","    (\"fast_complex\", PROMPT_COMPLEX, IMAGE_DIR_FAST_COMPLEX), # NEW\n","]\n","\n","print(\"--- Starting CLIP Score Calculation ---\")\n","\n","for key, prompt, folder in tasks:\n","    if os.path.exists(folder):\n","        print(f\"\\nCalculating for: {key}\")\n","        score = compute_clip_score_for_folder(folder, prompt)\n","        quality_scores[key] = score\n","        print(f\" -> Score: {score:.4f}\")\n","    else:\n","        print(f\"\\nWarning: Folder not found for {key}: {folder}\")\n","\n","# --- 2. Update and Save JSON ---\n","print(f\"\\n--- Updating JSON file at: {OUTPUT_JSON_PATH} ---\")\n","\n","try:\n","    if os.path.exists(OUTPUT_JSON_PATH):\n","        with open(OUTPUT_JSON_PATH, 'r') as f:\n","            final_results = json.load(f)\n","    else:\n","        final_results = {\"run_config\": {\"gpu_type\": \"NVIDIA T4\"}}\n","        print(\"Warning: No existing JSON found. Creating new one.\")\n","\n","    # Map short keys to JSON config keys\n","    key_mapping = {\n","        \"high_simple\": \"config_high_simple\",\n","        \"high_comic\": \"config_high_comic\",\n","        \"high_complex\": \"config_high_complex\",\n","        \"fast_simple\": \"config_fast_simple\",\n","        \"fast_comic\": \"config_fast_comic\",\n","        \"fast_complex\": \"config_fast_complex\"\n","    }\n","\n","    for short_key, json_key in key_mapping.items():\n","        if short_key in quality_scores:\n","            # Ensure the key exists in JSON structure\n","            if json_key not in final_results:\n","                final_results[json_key] = {\"description\": f\"Added {short_key}\"}\n","\n","            # Update the score\n","            final_results[json_key][\"quality_clip_score\"] = quality_scores[short_key]\n","\n","    # Save back to file\n","    with open(OUTPUT_JSON_PATH, 'w') as f:\n","        json.dump(final_results, f, indent=4)\n","\n","    print(\"\\n Success! JSON updated with all 6 CLIP scores.\")\n","\n","except Exception as e:\n","    print(f\"Error saving JSON: {e}\")"],"metadata":{"id":"4RVcJsaXDWW8"},"execution_count":null,"outputs":[]}]}